[gpt]
model_name=gpt
max_pos_seq_len=2048 ;for position embedding tables
head_num=12
size_per_head=64
inter_size=3072
num_layer=12
vocab_size=50257
start_id=50256
end_id=50256
weight_data_type=fp32
prompt_learning_start_id=50257
prompt_learning_type=3
num_tasks=3

[task_0]
task_name=sentiment
prompt_length=10

[task_1]
task_name=intent_and_slot
prompt_length=10

[task_2]
task_name=squad
prompt_length=16