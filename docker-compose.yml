services:
  fastertransformer-triton-convert:
    build:
      dockerfile: Dockerfile
      args:
        - FROM_BASE_IMAGE=${FROM_BASE_IMAGE}
    image: fastertransformer-triton-convert
    network_mode: host
    shm_size: 64gb
    ulimits:
      memlock: -1
      stack: 67108864
    runtime: nvidia
    working_dir: /workspace
    volumes:
      - type: bind
        source: models/cache
        target: /root/.cache
      - type: bind
        source: models
        target: /models
      - type: bind
        source: FasterTransformer
        target: /workspace/FasterTransformer
      - type: bind
        source: fastertransformer_backend
        target: /workspace/fastertransformer_backend
      - type: bind
        source: entrypoint.sh
        target: /workspace/entrypoint.sh
    entrypoint: ["/workspace/entrypoint.sh"]

  fastertransformer-triton-server:
    build:
      dockerfile: docker/Dockerfile
      context: fastertransformer_backend
      args:
        - TRITON_VERSION=${TRITON_VERSION}
    image: fastertransformer-triton-server
    network_mode: host
    shm_size: 64gb
    ulimits:
      memlock: -1
      stack: 67108864
    runtime: nvidia
    working_dir: /workspace
    volumes:
      - type: bind
        source: models/cache
        target: /root/.cache
      - type: bind
        source: models
        target: /models
    entrypoint:
      [
        "tritonserver",
        "--model-repository=/models/triton_models/gpt",
        "--id=gpt-20b",
        "--allow-metrics=true",
        "--allow-gpu-metrics=true",
        "--log-verbose=0",
      ]

  fastertransformer-triton-client:
    build:
      dockerfile: Dockerfile
      args:
        - FROM_BASE_IMAGE=nvcr.io/nvidia/tritonserver:${TRITON_VERSION}-py3
    image: fastertransformer-triton-client
    network_mode: host
    shm_size: 64gb
    ulimits:
      memlock: -1
      stack: 67108864
    runtime: nvidia
    volumes:
      - type: bind
        source: workspace
        target: /workspace
    working_dir: /workspace
    environment:
      - PYTHONPATH=/workspace
      - PYTHONUNBUFFERED=1
      - GRADIO_ALLOW_FLAGGING=never
      - GRADIO_ANALYTICS_ENABLED=0
      - GRADIO_NUM_PORTS=1
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=8889
    entrypoint: ["python3", "/workspace/app.py"]
    #   [
    #     "jupyter",
    #     "lab",
    #     "--ServerApp.ip=0.0.0.0",
    #     "--ServerApp.port=8888",
    #     "--ServerApp.allow_root=True",
    #     "--ServerApp.token=''",
    #     "--ServerApp.password=''",
    #     "--no-browser",
    #   ]

  fastertransformer-performance-analyzer:
    image: fastertransformer-triton-server
    network_mode: host
    shm_size: 64gb
    depends_on: 
      - fastertransformer-triton-server
    ulimits:
      memlock: -1
      stack: 67108864
    privileged: true
    volumes:
      - type: bind
        source: workspace
        target: /workspace
    working_dir: /workspace
    entrypoint: ["/workspace/run_perf_analyzer.sh"]
