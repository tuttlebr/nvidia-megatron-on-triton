{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "from tritonclient.utils import np_to_triton_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"localhost:8000\"\n",
    "MODEL = \"ensemble\"\n",
    "IS_RETURN_LOG_PROBS = True\n",
    "START_ID = 220\n",
    "END_ID = 50256\n",
    "RANDOM_SEED = 0\n",
    "BAD_WORDS_LIST = [\"\"]\n",
    "client = httpclient.InferenceServerClient(URL, concurrency=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensor(name, input):\n",
    "    tensor = httpclient.InferInput(\n",
    "        name, input.shape, np_to_triton_dtype(input.dtype))\n",
    "    tensor.set_data_from_numpy(input)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(data):\n",
    "    bad_words_list = np.array([data[\"bad_words_list\"]], dtype=object)\n",
    "    stop_words_list = np.array([data[\"stop_words_list\"]], dtype=object)\n",
    "    input0_data = np.array(data[\"prompt\"]).astype(object)\n",
    "    output0_len = np.ones_like(data[\"prompt\"]).astype(np.uint32) * data[\"tokens_to_generate\"]\n",
    "    runtime_top_k = (data[\"runtime_top_k\"] * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    runtime_top_p = data[\"runtime_top_p\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    beam_search_diversity_rate = data[\"beam_search_diversity_rate\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    temperature = data[\"temperature\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    len_penalty = data[\"len_penalty\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    repetition_penalty = data[\"repetition_penalty\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    random_seed = data[\"random_seed\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint64)\n",
    "    is_return_log_probs = data[\"is_return_log_probs\"] * np.ones([input0_data.shape[0], 1]).astype(bool)\n",
    "    beam_width = (data[\"beam_width\"] * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    start_id = data[\"start_id\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    end_id = data[\"end_id\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "\n",
    "    inputs = [\n",
    "        prepare_tensor(\"INPUT_0\", input0_data),\n",
    "        prepare_tensor(\"INPUT_1\", output0_len),\n",
    "        prepare_tensor(\"INPUT_2\", bad_words_list),\n",
    "        prepare_tensor(\"INPUT_3\", stop_words_list),\n",
    "        prepare_tensor(\"runtime_top_k\", runtime_top_k),\n",
    "        prepare_tensor(\"runtime_top_p\", runtime_top_p),\n",
    "        prepare_tensor(\"beam_search_diversity_rate\", beam_search_diversity_rate),\n",
    "        prepare_tensor(\"temperature\", temperature),\n",
    "        prepare_tensor(\"len_penalty\", len_penalty),\n",
    "        prepare_tensor(\"repetition_penalty\", repetition_penalty),\n",
    "        prepare_tensor(\"random_seed\", random_seed),\n",
    "        prepare_tensor(\"is_return_log_probs\", is_return_log_probs),\n",
    "        prepare_tensor(\"beam_width\", beam_width),\n",
    "        prepare_tensor(\"start_id\", start_id),\n",
    "        prepare_tensor(\"end_id\", end_id),\n",
    "    ]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2debb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_outputs(result):\n",
    "    completions = result.as_numpy(\"OUTPUT_0\")\n",
    "    formatted_completions = []\n",
    "    for completion in completions:\n",
    "        tmp_string = completion.decode(\"utf-8\")\n",
    "        tmp_string = re.sub('<\\|endoftext\\|>', \"\", tmp_string)\n",
    "        formatted_completions.append(tmp_string)\n",
    "        \n",
    "    return formatted_completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f64d48",
   "metadata": {},
   "source": [
    "## Sample Prompts\n",
    "\n",
    "### Tuning Parameters\n",
    "| **Parameter** | **Description** |\n",
    "|---|---|\n",
    "| Number of Tokens | _Specifies how much text to generate. Tokens can be either an entire word, or parts of words. For English, 100 tokens form approximately 75 words._ |\n",
    "| Temperature | _Controls the randomness of selecting the next token during text generation. Lower values reduce randomness, suitable for tasks with a correct answer such as question answering or summarization. Higher values increase randomness, suitable for tasks that require creativity. The [0.5, 0.8] range is a good starting point for experimentation._ |\n",
    "| Top K | _Controls the randomness of selecting the next token during text generation. The number of highest-probability tokens to keep, from which the next token will be selected at random. Lower values reduce randomness, suitable for tasks with a correct answer such as question answering or summarization. Higher values increase randomness, suitable for tasks that require creativity. 0 means Top K is not used. 1 means greedy decoding, that is, always selecting the most probable token next._ |\n",
    "| Top P | _Controls the randomness of selecting the next token during text generation. This determines the minimum number of highest-probability tokens whose probabilities sum to or exceed the Top P value, from which the next token will be selected at random. Lower values reduce randomness, suitable for tasks with a correct answer such as question answering or summarization. Higher values increase randomness, suitable for tasks that require creativity._ |\n",
    "| Repetition Penalty | _How much to penalize tokens based on how frequently they occur in the text. A value of 1 means no penalty, while values larger than 1 discourage repeated tokens._ |\n",
    "| Length Penalty | _Only applies to beam search, that is, when the beam width is >1. Larger values penalize long candidates more heavily thus preferring shorter candidates._ |\n",
    "| Beam Search Diversity Rate | _Only applies to beam search, that is, when the beam width is >1. A higher value encourages beam search to return a more diverse set of candidates._ |\n",
    "| Beam Width | _The number of concurrent candidates to keep track of during beam search. Higher values increase the chance of finding a good output but also require more computation. Streaming is supported with a “beam width” hyperparameter set to 1 only._ |\n",
    "| Random Seed | _The model generates random results. Changing the random seed alone will produce a different response with similar characteristics. It is possible to reproduce results by fixing the random seed (assuming all other hyperparameters are also fixed)._ |\n",
    "| Stop Words | _Set of character sequences, upon generating any of which, the API will stop generating any further text prematurely, even if the output length has not yet reached the specified number of tokens. It is useful to design a stopping template in the examples given to the model so that it can learn to stop appropriately upon completing an intended task._ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9959f09",
   "metadata": {},
   "source": [
    "### AI Chatbot QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4726722",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = {\n",
    "    \"prompt\": [[\"Misty is a cheerful AI assistant and companion, created by NVIDIA engineers. Misty is clever and helpful, and will do everything it can to cheer you up:\\n\\nYou: How are you feeling?\\nMisty: I'm feeling great, how may I help you today?\\nYou: Can you please suggest a movie?\\nMisty: How about \\\"The Martian\\\". It's a sci-fi movie about an astronaut getting stranded on Mars!\\nYou: That's cool! But i'm in the mood for watching comedy today\\nMisty:\"]],\n",
    "    \"stop_words_list\": [\"You:\"],\n",
    "    \"tokens_to_generate\": 40,\n",
    "    \"temperature\": 0.5,\n",
    "    \"runtime_top_k\": 2,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(chatbot)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f8cee",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization = {\n",
    "    \"prompt\": [[\"Summarize the following article:\\nArticle: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\\n\\nSummary: The Transformer architecture based solely on the attention mechanism deliver superior quality on several translation tasks while being more parallelizable and requiring significantly less time to train compared to recurrence and convolution alternatives.\\n\\n===\\n\\nSummarize the following article:\\nArticle: In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.\\n\\nSummary:\"]],\n",
    "    \"stop_words_list\": [\"===\",\"\\n\\n\"],\n",
    "    \"tokens_to_generate\": 64,\n",
    "    \"temperature\": 0.5,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(summarization)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca877546",
   "metadata": {},
   "source": [
    "### Open Domain Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53159df",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_domain_qa = {\n",
    "    \"prompt\": [[\"Q: What is the capital of Spain? \\nA: Madrid\\n\\nQ: What is synthetic biology?\\nA: Synthetic Biology is about designing biological systems at multiple levels from individual molecules up to whole cells and even multicellular assemblies like tissues and organs to perform specific functions.\\n\\nQ: What are the greatest threats of climate change?\\nA: The greatest threats of climate change are rising sea levels, extreme weather events, and droughts.\\n\\nQ: What roles do proteins play in our cells?\\nA: Proteins within a cell determine its health and function. Proteins are responsible for nearly every task of cellular life, including cell shape and inner organization, product manufacture and waste cleanup, and routine maintenance. Proteins also receive signals from outside the cell and mobilize intracellular response. They are the workhorse macro molecules of the cell and are as diverse as the functions they serve.\\n\\nQ: What is the largest source of uncertainty in climate sensitivity?\\nA:\"]],\n",
    "    \"stop_words_list\": [\"Q:\",\"\\\\n\"],\n",
    "    \"tokens_to_generate\": 48,\n",
    "    \"temperature\": 0.2,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(open_domain_qa)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5034bc6",
   "metadata": {},
   "source": [
    "### Structured Data Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data_qa = {\n",
    "    \"prompt\": [[\"| Company Name | Number of Employees | Year Established | IPO Date | Share Price |\\n| Providence Inc. | 250 | 1990 | 25th August 1990 | $0.90 |\\n| Grant Corporation | 2000 | 1890 | 21st September 1920 | $115.90 |\\n| Rusty Metalworks | 12459 | 1946 | 12th September 1986 | $15.23 |\\n| Dull Knives &  Blades | 3412 | 2008 | 1st December 2012 | $3.20 |\\n\\n\\nQ: Which company has the most employees?\\nA: Rusty Metalworks\\n\\nQ: When was Grant Corporation established?\\nA: 21st September 1920\\n\\nQ: Which company had the most recent IPO date?\\nA: Dull Knives & Blades\\n\\nQ: What is the share price and IPO date of Rusty Metalworks?\\nA:\"]],\n",
    "    \"stop_words_list\": [\"Q:\"],\n",
    "    \"tokens_to_generate\": 32,\n",
    "    \"temperature\": 0.2,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(structured_data_qa)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3d150",
   "metadata": {},
   "source": [
    "### Unstructured Data Q & A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured_data_qa = {\n",
    "    \"prompt\": [[\"Date: 6/06/22\\nTime: 3 pm\\n\\nAttendees NVIDIA: Jane, Darby, Jerry\\nAttendees Peach Corp: Ram, Eva, Harry\\n\\n* Explored Product X\\n* Feature Request for adding backward compatibility with PyTorch 1.1\\n* Liked Feature A\\n* Willing to proceed with adoption if feature request is fulfilled.\\n-----------------------------------\\nDate: 5/30/22\\nTime: 10 am\\n\\nAttendees NVIDIA: Jane, Jone, Jerry\\nAttendees Peach Corp: Adam, Eva, Harry\\n\\n* Product X was introduced, initial response was lukewarm\\n* Peach Corp agreed to evaluate product X. 2 Engineers allocated for Exploration\\n* Looking for a cost analysis. Jane to send.\\n* Mainly interested in feature A\\n* Concerned about compatibility with PyTorch 1.1\\n* Do not want to spend resources on updating stack to support streaming Feature B\\n* Jane to set up follow-up call Friday next week for feedback on feature A\\n-----------------------------------\\nQ: What are the action items for NVIDIA attendees?\\nA: \"]],\n",
    "    \"stop_words_list\": [\"Q:\"],\n",
    "    \"tokens_to_generate\": 32,\n",
    "    \"temperature\": 0.2,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.8,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(unstructured_data_qa)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d5ecd",
   "metadata": {},
   "source": [
    "### Blog Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_post = {\n",
    "    \"prompt\": [[\"Generate a blog intro for the following topic: speechAI\\nSpeech AI is the ability of intelligent systems to communicate with users using a voice-based interface, which has become ubiquitous in everyday life. People regularly interact with smart home devices, telephone banking services, and phones via speech. Speech interface quality has improved leaps and bounds in recent years, making them a much more pleasant, practical, and natural experience than just a decade ago. In this blog, we will present the workflow, tools, and best practices that the NVIDIA engineering team employed to make new world-class Riva SpeechAI services. Let's start this journey!\\n\\n===\\n\\nGenerate a blog intro for the following topic: TensorRT\\n\"]],\n",
    "    \"stop_words_list\": [\"===\",\"\\n\\n\"],\n",
    "    \"tokens_to_generate\": 128,\n",
    "    \"temperature\": 0.5,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(blog_post)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fad139",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = {\n",
    "    \"prompt\": [[\"Classify the following articles into one of three topics: Politics, Sport and Science\\n\\nArticle: Britain’s plan to become a 'science and technology superpower' is so lacking in focus and so full of new organisational structures that the country risks becoming a 'bureaucracy superpower' instead, an influential crossbench peer has said.\\nClass: Politics\\n\\nArticle: It is the middle of the European winter, and sprinter Evan O'Hanlon is shovelling snow off a track in the Czech Republic, where he lives, so he can train in -8C weather. \\nClass: Sport\\n\\nArticle: NASA is 'in the final stretch' of launching its Artemis I mission as it will roll out the worlds most powerful rocket, the Space Launch System (SLS), and the Orion capsule to the launch pad in just two weeks.\\nNASA Administrator Bill Nelson said during a Wednesday briefing: 'This is now the Artemis generation,' Nelson said.\\nClass: Science\\n\\nArticle: The Cartwheel Galaxy, also known as ESO 350-40 or PGC 2248, is a rare ring galaxy located about 500 million light-years away in the Sculptor constellation. The Cartwheel Galaxy, seen largest in the image below, resulted from an intense high-speed collision between a large spiral galaxy and a smaller galaxy that's not visible. The Webb team writes, 'Collisions of galactic proportions cause a cascade of different, smaller events between the galaxies involved; the Cartwheel is no exception.'\\nClass:\"]],\n",
    "    \"stop_words_list\": [\"\\n\"],\n",
    "    \"tokens_to_generate\": 5,\n",
    "    \"temperature\": 0.2,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0.0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(classification)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27c64c",
   "metadata": {},
   "source": [
    "### Write Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_code = {\n",
    "    \"prompt\": [[\"Generate python code that prints each item in a list.\\n\\nCode:\\nitem_list = [1,2,3,4,5]\\nfor i in item_list:\\n\\tprint(i)\\n\\n===\\n\\nGenerate python code that prints each item in a list if it's an even number.\\nCode:\"]],\n",
    "    \"stop_words_list\": [\"===\",\"\\n\\n\"],\n",
    "    \"tokens_to_generate\": 64,\n",
    "    \"temperature\": 0.7,\n",
    "    \"runtime_top_k\": 0,\n",
    "    \"runtime_top_p\": 1.0,\n",
    "    \"beam_search_diversity_rate\": 0,\n",
    "    \"beam_width\": 1,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"len_penalty\": 1.0,\n",
    "    \"is_return_log_probs\": IS_RETURN_LOG_PROBS,\n",
    "    \"start_id\": START_ID,\n",
    "    \"end_id\": END_ID,\n",
    "    \"bad_words_list\": BAD_WORDS_LIST,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "inputs = prepare_inputs(write_code)\n",
    "result = client.infer(MODEL, inputs)\n",
    "completions = prepare_outputs(result)\n",
    "for i in completions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85d99f-005e-4441-ade8-83fe491645a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_perf_analyzer(data):\n",
    "    bad_words_list = np.array([data[\"bad_words_list\"]], dtype=object)\n",
    "    stop_words_list = np.array([data[\"stop_words_list\"]], dtype=object)\n",
    "    input0_data = np.array(data[\"prompt\"]).astype(object)\n",
    "    output0_len = np.ones_like(data[\"prompt\"]).astype(np.uint32) * data[\"tokens_to_generate\"]\n",
    "    runtime_top_k = (data[\"runtime_top_k\"] * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    runtime_top_p = data[\"runtime_top_p\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    beam_search_diversity_rate = data[\"beam_search_diversity_rate\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    temperature = data[\"temperature\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    len_penalty = data[\"len_penalty\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    repetition_penalty = data[\"repetition_penalty\"] * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    random_seed = data[\"random_seed\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint64)\n",
    "    is_return_log_probs = data[\"is_return_log_probs\"] * np.ones([input0_data.shape[0], 1]).astype(bool)\n",
    "    beam_width = (data[\"beam_width\"] * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    start_id = data[\"start_id\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    end_id = data[\"end_id\"] * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    \n",
    "    json_input = {\n",
    "        \"INPUT_0\": {\"content\": input0_data.reshape(-1).tolist(), \"shape\": [1]},\n",
    "        \"INPUT_1\": {\"content\": output0_len.astype(object).reshape(-1).tolist(), \"shape\": [1]},\n",
    "        \"INPUT_2\": {\"content\": bad_words_list.reshape(-1).tolist(), \"shape\": [bad_words_list.shape[1]]},\n",
    "        \"INPUT_3\": {\"content\": stop_words_list.reshape(-1).tolist(), \"shape\": [stop_words_list.shape[1]]},\n",
    "        \"runtime_top_k\": runtime_top_k.reshape(-1).tolist(),\n",
    "        \"runtime_top_p\": runtime_top_p.reshape(-1).tolist(),\n",
    "        \"beam_search_diversity_rate\": beam_search_diversity_rate.reshape(-1).tolist(),\n",
    "        \"temperature\": temperature.reshape(-1).tolist(),\n",
    "        \"len_penalty\": len_penalty.reshape(-1).tolist(),\n",
    "        \"repetition_penalty\": repetition_penalty.reshape(-1).tolist(),\n",
    "        \"random_seed\": random_seed.reshape(-1).tolist(),\n",
    "        \"is_return_log_probs\": is_return_log_probs.reshape(-1).tolist(),\n",
    "        \"beam_width\": beam_width.reshape(-1).tolist(),\n",
    "        \"start_id\": start_id.reshape(-1).tolist(),\n",
    "        \"end_id\": end_id.reshape(-1).tolist()\n",
    "    }\n",
    "    return json_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422ab35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_input = [chatbot, summarization, open_domain_qa, structured_data_qa, unstructured_data_qa, blog_post, classification, write_code]\n",
    "perf_analyzer_list = []\n",
    "\n",
    "\n",
    "for i in raw_data_input:\n",
    "    perf_analyzer_list.append(prepare_perf_analyzer(i))\n",
    "                              \n",
    "perf_analyzer_data = {\"data\": perf_analyzer_list}\n",
    "\n",
    "with open(\"perf_analyzer_data.json\", \"w\") as f:\n",
    "    json.dump(perf_analyzer_data, f)\n",
    "    \n",
    "perf_analyzer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894b456-c6c5-4b29-82d1-d9445a8f498d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b2bb6-bf86-4c5e-84b2-94b009b049e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
